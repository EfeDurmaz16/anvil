llm:
  # provider: anthropic, openai, groq, huggingface, ollama, together, deepseek, custom, none
  provider: ollama
  model: "qwen2.5-coder:7b"
  api_key: ""
  base_url: "http://localhost:11434/v1"
  temperature: 0.2
  max_tokens: 4096

graph:
  uri: bolt://localhost:7687
  username: neo4j
  password: password

vector:
  host: localhost
  port: 6334
  collection: anvil

temporal:
  host: localhost:7233
  namespace: default
  task_queue: anvil-tasks

log:
  level: info
  format: json
